
============================================================
Parameter estimation using grid search with cross-validation
============================================================

This examples shows how a classifier is optimized by cross-validation,
which is done using the :class:`sklearn.grid_search.GridSearchCV` object
on a development set that comprises only half of the available labeled data.

The performance of the selected hyper-parameters and trained model is
then measured on a dedicated evaluation set that was not used during
the model selection step.

More details on tools available for model selection can be found in the
sections on :ref:`cross_validation` and :ref:`grid_search`.


# Tuning hyper-parameters for precision

Best parameters set found on training set:

{'min_samples_split': 128, 'min_samples_leaf': 5, 'compute_importances': True, 'max_features': 100, 'max_depth': 10}
Detailed classification report:

Scores on training set.
             precision    recall  f1-score   support

          0       0.85      0.99      0.91      1308
          1       0.73      0.16      0.26       280

avg / total       0.83      0.84      0.80      1588


Scores on test set.

             precision    recall  f1-score   support

          0       0.81      0.98      0.89       315
          1       0.57      0.10      0.17        82

avg / total       0.76      0.80      0.74       397


# Tuning hyper-parameters for recall

Best parameters set found on training set:

{'min_samples_split': 2, 'min_samples_leaf': 1, 'compute_importances': True, 'max_features': 75, 'max_depth': 20}
Detailed classification report:

Scores on training set.
             precision    recall  f1-score   support

          0       0.99      1.00      1.00      1308
          1       1.00      0.96      0.98       280

avg / total       0.99      0.99      0.99      1588


Scores on test set.

             precision    recall  f1-score   support

          0       0.86      0.86      0.86       315
          1       0.46      0.45      0.46        82

avg / total       0.78      0.78      0.78       397


# Tuning hyper-parameters for f1

Best parameters set found on training set:

{'min_samples_split': 32, 'min_samples_leaf': 1, 'compute_importances': True, 'max_features': 100, 'max_depth': 10}
Detailed classification report:

Scores on training set.
             precision    recall  f1-score   support

          0       0.89      0.96      0.92      1308
          1       0.71      0.42      0.53       280

avg / total       0.86      0.87      0.85      1588


Scores on test set.

             precision    recall  f1-score   support

          0       0.83      0.93      0.88       315
          1       0.51      0.27      0.35        82

avg / total       0.76      0.80      0.77       397


